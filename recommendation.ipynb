{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import multiprocessing as mp\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "import torch\n",
    "from pygcn.utils import sparse_mx_to_torch_sparse_tensor\n",
    "from gcn import load_news_data, GCN_1layer\n",
    "\n",
    "from user_network import UserNetwork\n",
    "from utils import select_nodes_table, pytorch_cos_sim\n",
    "from utils import get_media_name_via_NewsIndex, get_media_name_via_NewsURL, clean_media_NewsURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sshtunnel\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "from mysql.connector import pooling\n",
    "\n",
    "ssh_host = '140.114.55.4'\n",
    "ssh_username = 'user'\n",
    "ssh_password = 'Nthuieem@42198'\n",
    "database_username = 'NRS'\n",
    "database_password = '70933980'\n",
    "database_name = 'NRS'\n",
    "localhost = '127.0.0.1'\n",
    "\n",
    "def open_ssh_tunnel(verbose=False):\n",
    "    \"\"\"Open an SSH tunnel and connect using a username and password.\n",
    "    :param verbose: Set to True to show logging\n",
    "    :return tunnel: Global SSH tunnel connection\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        sshtunnel.DEFAULT_LOGLEVEL = logging.DEBUG\n",
    "    global tunnel\n",
    "    tunnel = SSHTunnelForwarder(\n",
    "        (ssh_host, 22),\n",
    "        ssh_username = ssh_username,\n",
    "        ssh_password = ssh_password,\n",
    "        remote_bind_address = ('140.114.55.4', 3306)\n",
    "    )\n",
    "    tunnel.start()\n",
    "\n",
    "def close_ssh_tunnel():\n",
    "    \"\"\"Closes the SSH tunnel connection.\"\"\"\n",
    "    tunnel.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ssh_tunnel(verbose=False)\n",
    "\n",
    "dbpool = pooling.MySQLConnectionPool(\n",
    "    pool_size=5,\n",
    "    pool_reset_session=True,\n",
    "    host='127.0.0.1',\n",
    "    database=database_name,\n",
    "    user=database_username,\n",
    "    password=database_password,\n",
    "    port=tunnel.local_bind_port\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(matrix):\n",
    "    minima, maxima = matrix.min(), matrix.max()\n",
    "    return (matrix - minima)/(maxima - minima)\n",
    "\n",
    "def standadization(matrix):\n",
    "    mean, mu = matrix.mean(), matrix.mu()\n",
    "    return (matrix - mean)/(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_news_recommendation(NewsIndex, gcn_similarity_matrix, TOP_N):\n",
    "    single_news_recommendation = []\n",
    "    NewsIndex_idx = idx_NewsIndex_map[NewsIndex]\n",
    "    recommend_idx_list = gcn_similarity_matrix[NewsIndex_idx].argsort()[::-1][:TOP_N*3]\n",
    "    \n",
    "    for idx in recommend_idx_list:\n",
    "        recommend_NewsIndex = NewsIndex_list[idx_list.index(idx)]\n",
    "        score = gcn_similarity_matrix[NewsIndex_idx][idx]\n",
    "        if recommend_NewsIndex==NewsIndex: \n",
    "            continue\n",
    "        media_name = get_media_name_via_NewsIndex(recommend_NewsIndex)\n",
    "        x = select_nodes_table(DB_PATH, media_name+'news', '*', \"NewsIndex=='%s'\" %(recommend_NewsIndex))\n",
    "        if x==[]: \n",
    "            continue\n",
    "        x = x[0]\n",
    "        NewsIndex, NewsDate = x[0], x[3]\n",
    "        NewsTitle, NewsContext = x[4].replace(\"'\",\"\"), x[5].replace(\"'\",\"\")\n",
    "        if '綠光人間條件' in NewsContext:\n",
    "            continue\n",
    "        if NewsTitle not in [k[2] for k in single_news_recommendation]:\n",
    "#             [NewsIndex, NewsDate, NewsTitle, NewsContext, sim_score]\n",
    "            single_news_recommendation.append([NewsIndex, NewsDate, NewsTitle, NewsContext, float(score)])\n",
    "        \n",
    "        # sort by NewsDate\n",
    "        single_news_recommendation = sorted(single_news_recommendation, key=lambda x:x[1], reverse=True)\n",
    "    return single_news_recommendation[:TOP_N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cluster_recommendation(cluster, REC_LEN):\n",
    "    recommendation_list = []\n",
    "    for NewsIndex in cluster:\n",
    "        recommendation_list += generate_single_news_recommendation(NewsIndex, gcn_similarity_matrix, TOP_N)\n",
    "        \n",
    "    cluster_recommendation = []\n",
    "    for k in recommendation_list:\n",
    "        if k[2] not in [n[2] for n in cluster_recommendation]:\n",
    "            cluster_recommendation.append(k)\n",
    "            \n",
    "    cluster_recommendation = sorted(cluster_recommendation, key=lambda x:x[1], reverse=True) # sort by NewsDate\n",
    "#     cluster_recommendation = [k for k in cluster_recommendation if k[1]==TODAY_DATE] # filter NewsDate\n",
    "    cluster_recommendation = cluster_recommendation[:REC_LEN]\n",
    "    \n",
    "    for r in cluster_recommendation:\n",
    "        print('%s %s %s %s' %(r[0], r[1], r[2], r[4]))\n",
    "    return cluster_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_recommendation(user_history, user_interests_cluster, TOTAL_REC_LEN):\n",
    "    \"\"\"\n",
    "    TOTAL_REC_LEN: Expected final recommendation list length\n",
    "    SCALE: Impotance of an interests cluster (i.e. the propotion within all news)\n",
    "    CLUSTER_REC_LEN: # of rec news for interests cluster i = len(news in cluster i)/len(total user history news)\n",
    "    \"\"\"\n",
    "    SCALE = len(user_history) / TOTAL_REC_LEN \n",
    "    total_len = 0\n",
    "    recommendation_list = []\n",
    "    for i, cluster in enumerate(user_interests_cluster):\n",
    "        CLUSTER_REC_LEN = math.ceil(len(cluster) / SCALE)\n",
    "        print('\\n----------cluster %d-----------\\n' %(i+1))\n",
    "        print('Original cluster len %d, recommend %d news' %(len(cluster), CLUSTER_REC_LEN))\n",
    "        recommendation_list += generate_cluster_recommendation(cluster, CLUSTER_REC_LEN)\n",
    "        total_len += CLUSTER_REC_LEN\n",
    "        if total_len >= TOTAL_REC_LEN:\n",
    "            break\n",
    "    \n",
    "    user_history_NewsTitle = []\n",
    "    for NewsIndex in user_history:\n",
    "        media_name = get_media_name_via_NewsIndex(NewsIndex)\n",
    "        x = select_nodes_table(DB_PATH, media_name+'news', 'NewsTitle', \"NewsIndex=='%s'\" %(NewsIndex))\n",
    "        user_history_NewsTitle.append(x[0][0])\n",
    "    user_recommendation = []\n",
    "    for k in recommendation_list:\n",
    "        if k[2] not in user_history_NewsTitle:\n",
    "            user_recommendation.append(k)\n",
    "            \n",
    "    final_recommendation = []\n",
    "    for k in user_recommendation:\n",
    "        if k[2] not in [n[2] for n in final_recommendation] and k[0] not in [n[0] for n in final_recommendation]:\n",
    "            final_recommendation.append(k)\n",
    "\n",
    "    final_recommendation = final_recommendation[:TOTAL_REC_LEN]\n",
    "    return final_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_user_history_url(url):\n",
    "    media_name = get_media_name_via_NewsURL(url)\n",
    "    if media_name==None: # Check url belong to news media\n",
    "#         print('News url not belong: %s' %url)\n",
    "        return None\n",
    "    url = clean_media_NewsURL(media_name, url)\n",
    "    if url==None: # Check url correctness of each news media\n",
    "#         print('News url not correct: %s' %url)\n",
    "        return None\n",
    "    x = select_nodes_table(DB_PATH, media_name+'news', 'NewsIndex', \"NewsURL LIKE '%{}%'\".format(url))\n",
    "    if x==[]: # Check is parsed or not\n",
    "#         print('News not found in sql: %s' %url)\n",
    "        return None\n",
    "    NewsIndex = x[0][0]\n",
    "    if NewsIndex not in NewsIndex_list: # Check in cross-news-network\n",
    "#         print('News not found in cross-news-network: %s' %url)\n",
    "        return None\n",
    "    return NewsIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_user_history_from_lab_sql(TODAY_DATE, USER_NAME, EXP_D):\n",
    "    QUERY_DATE = (datetime.datetime.strptime(TODAY_DATE, \"%Y-%m-%d\") - \n",
    "                  datetime.timedelta(days=EXP_D)).strftime('%Y-%m-%d')\n",
    "#     print('%s - %s' %(QUERY_DATE, TODAY_DATE))\n",
    "    sql = \"SELECT NewsURL FROM UserRead WHERE User='%s' AND TodayDate<'%s' AND TodayDate>='%s'\" %(USER_NAME, TODAY_DATE, QUERY_DATE)\n",
    "    con = dbpool.get_connection()\n",
    "    cur = con.cursor(buffered=True)\n",
    "    cur.execute(sql)\n",
    "    user_history_url = cur.fetchall()\n",
    "    cur.close()\n",
    "    con.close()\n",
    "    \n",
    "    user_history = []\n",
    "    for k in user_history_url:\n",
    "        url = k[0]\n",
    "        x = check_user_history_url(url)\n",
    "        if x!=None:\n",
    "            user_history.append(x)\n",
    "    return user_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_recommendation_to_lab_sql(USER_NAME, TODAY_DATE, final_recommendation):\n",
    "    if TIME_VERSION==12:\n",
    "        table_name = 'UserRecommendation1'\n",
    "    else:\n",
    "        table_name = 'UserRecommendation2'\n",
    "    print('Insert into %s' %(table_name))\n",
    "    \n",
    "    con = dbpool.get_connection()\n",
    "    cur = con.cursor(buffered=True)\n",
    "    \n",
    "    count = 0\n",
    "    user = USER_NAME\n",
    "    today_date = TODAY_DATE\n",
    "    for i, k in enumerate(final_recommendation):\n",
    "        if len(k)!=5:\n",
    "            continue\n",
    "        NewsIndex = k[0]\n",
    "        NewsDate = k[1]\n",
    "        NewsTitle = k[2]\n",
    "        NewsContext = k[3].encode('utf8').decode('utf8')\n",
    "        ExpDays = k[4]\n",
    "        \n",
    "        check_exist_sql = \"\"\"SELECT * FROM %s WHERE USER='%s' AND TodayDate='%s' AND NewsIndex='%s'\n",
    "                            AND NewsDate='%s' AND NewsTitle='%s' AND ExpDays='%s'\"\"\" %(table_name, user, today_date, NewsIndex, NewsDate, NewsTitle, ExpDays) \n",
    "        cur.execute(check_exist_sql)\n",
    "        check_exist=False if cur.fetchall()==[] else True\n",
    "        if check_exist==False:\n",
    "            try:\n",
    "                sql = '''INSERT INTO %s (USER,TodayDate,NewsIndex,NewsDate,NewsTitle,NewsContext,ExpDays) \n",
    "                VALUES ('%s','%s','%s','%s','%s','%s','%s')''' %(table_name, user, today_date, NewsIndex, NewsDate, NewsTitle, NewsContext, ExpDays)\n",
    "                cur.execute(sql)\n",
    "                count+=1\n",
    "            except:\n",
    "                print('[Warning] Failed to insert sql')\n",
    "#         else:\n",
    "#             print('[Warning] Exist sql', NewsIndex)\n",
    "            \n",
    "    print('Success insert %d / %d' %(count, len(final_recommendation)))    \n",
    "    con.commit()\n",
    "    cur.close()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(DB_PATH, TODAY_DATE, USER_NAME, EXP_D):\n",
    "    user_history = select_user_history_from_lab_sql(TODAY_DATE, USER_NAME, EXP_D)\n",
    "    if len(user_history)==0:\n",
    "        print('[Warning] %s have no history news' %USER_NAME)\n",
    "        return\n",
    "    else:\n",
    "        print('%s read list length %d' %(USER_NAME, len(user_history)))\n",
    "    \n",
    "    user_history_NewsIndex = []\n",
    "    user_history_NewsEmb = []\n",
    "    for NewsIndex in user_history:\n",
    "        idx = idx_NewsIndex_map[NewsIndex]\n",
    "        user_history_NewsIndex.append(NewsIndex)\n",
    "        user_history_NewsEmb.append(NewsEmb_list[idx].tolist())\n",
    "    \n",
    "    UN = UserNetwork(DB_PATH, TODAY_DATE)\n",
    "    user_interests_network = UN.construct_user_interests_network(user_history_NewsIndex, user_history_NewsEmb, THRES)\n",
    "    user_interests_cluster = UN.generate_user_interests_network_cluster(user_interests_network)\n",
    "    UN.print_user_interests_network_cluster(user_interests_cluster)\n",
    "\n",
    "    user_recommendation = generate_user_recommendation(user_history, user_interests_cluster, TOTAL_REC_LEN)\n",
    "    \n",
    "    final_recommendation = [[k[0], k[1], k[2], k[3], '%dd'%(EXP_D)] for k in user_recommendation]\n",
    "    print('%s recommendation list length %d' %(USER_NAME, len(final_recommendation)) )\n",
    "    return final_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_recommendation_lists(list1, list2):\n",
    "    result = list2.copy()\n",
    "    list2_NewsTitle = [k[2] for k in list2]\n",
    "    \n",
    "    for i, k in enumerate(list1):\n",
    "        if k[2] in list2_NewsTitle: # list1 news in list2\n",
    "            idx = list2_NewsTitle.index(k[2])\n",
    "#             print(k[0], k[-1], result[idx][-1])\n",
    "            x = k[-1] + result[idx][-1]\n",
    "            result[idx] = [k[0], k[1], k[2], k[3], x]\n",
    "        else: # list1 news not in list2\n",
    "            result.append(k)\n",
    "    return result\n",
    "\n",
    "def cluster_recommendation_lists(user_history_NewsIndex):\n",
    "    user_history_NewsEmb = []\n",
    "    for NewsIndex in user_history_NewsIndex:\n",
    "        idx = idx_NewsIndex_map[NewsIndex]\n",
    "        user_history_NewsEmb.append(NewsEmb_list[idx].tolist())\n",
    "    \n",
    "    UN = UserNetwork(DB_PATH, TODAY_DATE)\n",
    "    user_interests_network = UN.construct_user_interests_network(user_history_NewsIndex, user_history_NewsEmb, THRES)\n",
    "    user_interests_cluster = UN.generate_user_interests_network_cluster(user_interests_network)\n",
    "    result = []\n",
    "    for cluster in user_interests_cluster:\n",
    "        for k in cluster:\n",
    "            result.append(k)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODAY_DATE 2021-06-29, TIME_VERSION 18, User length: 50\n"
     ]
    }
   ],
   "source": [
    "USERS = pd.read_csv('./exp2_users.csv')['姓名'].values.tolist()\n",
    "DB_PATH = './db/NewsNetwork_ch_20210629.db'\n",
    "TODAY_DATE = '2021-06-29'\n",
    "TIME_VERSION = 18\n",
    "\n",
    "EXP_W = 0.1\n",
    "EXP_W_NAME = str(EXP_W).replace('.','')\n",
    "# EXP_D = 1           # 1d / 3d / 5d\n",
    "THRES = 0.8         # User interests network edges thres\n",
    "TOTAL_REC_LEN = 20  # Total rec len\n",
    "TOP_N = 5           # Single news rec len\n",
    "\n",
    "print('TODAY_DATE %s, TIME_VERSION %d, User length: %d' %(TODAY_DATE, TIME_VERSION, len(USERS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_news_network_path = \"./cross-news-network/%s/%s\" %(TODAY_DATE, TIME_VERSION)\n",
    "\n",
    "gcn_model_path = \"./gcn-model/%s/%s\" %(TODAY_DATE, TIME_VERSION)\n",
    "model = torch.load(os.path.join(gcn_model_path, 'gcn_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "def generate_gcn_embeddings(model, adj, features):\n",
    "    no_cuda = False\n",
    "    if not no_cuda and torch.cuda.is_available():\n",
    "        print('[INFO] Use Cuda!')\n",
    "        model.cuda()\n",
    "        features, adj = features.cuda(), adj.cuda()\n",
    "    output = model(features, adj)\n",
    "    return output\n",
    "\n",
    "def normalization(matrix):\n",
    "    minima, maxima = matrix.min(), matrix.max()\n",
    "    return (matrix - minima)/(maxima - minima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset from ./cross-news-network/2021-06-29/18\n",
      "[INFO] Use Cuda!\n",
      "16.149110555648804\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "idx_NewsIndex_map, adj, features, X, Y = load_news_data(cross_news_network_path, EXP_W_NAME)\n",
    "\n",
    "NewsEmb_list = features.cpu().detach().numpy()\n",
    "NewsIndex_list = list(idx_NewsIndex_map.keys())\n",
    "idx_list = list(idx_NewsIndex_map.values())\n",
    "\n",
    "gcn_emb = generate_gcn_embeddings(model, adj, features)\n",
    "gcn_emb = gcn_emb.cpu().detach().numpy()\n",
    "gcn_similarity_matrix = 1 - pairwise_distances(gcn_emb, metric=\"cosine\")\n",
    "gcn_similarity_matrix = normalization(gcn_similarity_matrix)\n",
    "\n",
    "print(time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_total = time.time()\n",
    "\n",
    "for USER_NAME in ['徐家琇']:\n",
    "    s = time.time()\n",
    "    final_recommendation_1 = main(DB_PATH, TODAY_DATE, USER_NAME, EXP_D=1)\n",
    "    final_recommendation_3 = main(DB_PATH, TODAY_DATE, USER_NAME, EXP_D=3)\n",
    "    final_recommendation_5 = main(DB_PATH, TODAY_DATE, USER_NAME, EXP_D=5)\n",
    "    \n",
    "#     ty0626 merge 1d / 3d\n",
    "    if final_recommendation_1==None and final_recommendation_3==None:\n",
    "        continue\n",
    "    elif final_recommendation_1==None:\n",
    "#         final_recommendation = final_recommendation_3\n",
    "        merge2 = merge_recommendation_lists(final_recommendation_3, final_recommendation_5) # 1d 3d 5d\n",
    "    else:\n",
    "        merge1 = merge_recommendation_lists(final_recommendation_1, final_recommendation_3) # 1d 3d\n",
    "        merge2 = merge_recommendation_lists(merge1, final_recommendation_5) # 1d 3d 5d\n",
    "    rec_merge_list = merge2\n",
    "    rec_merge_NewsIndex = [k[0] for k in rec_merge_list]\n",
    "    rec_NewsIndex_order = cluster_recommendation_lists(rec_merge_NewsIndex)\n",
    "    final_recommendation = []\n",
    "    for NewsIndex in rec_NewsIndex_order:\n",
    "        idx = rec_merge_NewsIndex.index(NewsIndex)\n",
    "        final_recommendation.append(rec_merge_list[idx])\n",
    "    \n",
    "#     if final_recommendation!=None:\n",
    "#         insert_recommendation_to_lab_sql(USER_NAME, TODAY_DATE, final_recommendation)\n",
    "\n",
    "    print(time.time() - s)\n",
    "print(time.time() - s_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_ssh_tunnel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
